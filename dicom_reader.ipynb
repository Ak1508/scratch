{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4278aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ef71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the CT image\n",
    "ct_image = cv2.imread(\"ct_image.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(ct_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to create a binary image of the ROI\n",
    "ret, threshold_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find the contours in the binary image\n",
    "contours, _ = cv2.findContours(threshold_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the bounding box for the largest contour\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "# Draw the bounding box on the original image\n",
    "ct_image = cv2.rectangle(ct_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Show the image with the bounding box\n",
    "cv2.imshow(\"CT Image with Bounding Box\", ct_image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_roi_contour(dicom_path, roi_number):\n",
    "    # Read the DICOM file\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "\n",
    "    # Get the ROI Contour Sequence\n",
    "    roi_contours = ds.ROIContourSequence\n",
    "\n",
    "    # Iterate through the ROI Contours and find the one with the matching ROI Number\n",
    "    for item in roi_contours:\n",
    "        if item.ReferencedROINumber == roi_number:\n",
    "            # Get the Contour Sequence for the matching ROI\n",
    "            contour_sequence = item.ContourSequence\n",
    "\n",
    "            # Iterate through the Contour Sequence and print the coordinates\n",
    "            for contour in contour_sequence:\n",
    "                print(\"Contour Data:\", contour.ContourData)\n",
    "                print(\"Number of Points:\", contour.NumberOfContourPoints)\n",
    "\n",
    "# Example usage\n",
    "get_roi_contour('path/to/dicom/file.dcm', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_structure_set(dicom_path):\n",
    "    # Read the DICOM file\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "\n",
    "    # Get the structure set sequence\n",
    "    structure_set = ds.StructureSetROISequence\n",
    "\n",
    "    # Iterate through the structure set and print the information\n",
    "    for item in structure_set:\n",
    "        print(\"ROI Number:\", item.ROINumber)\n",
    "        print(\"ROI Name:\", item.ROIName)\n",
    "        print(\"ROI Description:\", item.ROIDescription)\n",
    "\n",
    "# Example usage\n",
    "get_structure_set('path/to/dicom/file.dcm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def GetContourPixelData(pixlut, contour, prone = False, feetfirst = False):\n",
    "    pixeldata = []\n",
    "    pixelX = []\n",
    "    pixelY = []\n",
    "    contour = np.array(contour)\n",
    "    \n",
    "    x_lut = np.array(pixlut[0])\n",
    "    y_lut = np.array(pixlut[1])\n",
    "    \n",
    "    xv, yv = np.searchsorted(x_lut, contour[:,0]), np.searchsorted(y_lut, contour[:,1])\n",
    "    \n",
    "    if prone:\n",
    "        yv = len(y_lut) - yv\n",
    "    if feetfirst or prone:\n",
    "        xv = len(x_lut) - xv\n",
    "    \n",
    "    pixeldata = np.column_stack((xv, yv))\n",
    "    pixelX, pixelY = xv, yv\n",
    "    \n",
    "    return pixeldata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "def get_pixlut_from_dicom(dicom_file):\n",
    "    # Open the DICOM file\n",
    "    ds = pydicom.dcmread(dicom_file)\n",
    "\n",
    "    # Get the image position and orientation\n",
    "    image_position = ds.ImagePositionPatient\n",
    "    image_orientation = ds.ImageOrientationPatient\n",
    "\n",
    "    # Create the LUT\n",
    "    pixlut = [image_position, image_orientation]\n",
    "    return pixlut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dede00",
   "metadata": {},
   "source": [
    "## Creating class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "class DicomContour:\n",
    "    def __init__(self, dicom_file):\n",
    "        self.dicom_file = dicom_file\n",
    "        self.pixlut = self.get_pixlut_from_dicom()\n",
    "    \n",
    "    def get_pixlut_from_dicom(self):\n",
    "        # Open the DICOM file\n",
    "        ds = pydicom.dcmread(self.dicom_file)\n",
    "\n",
    "        # Get the image position and orientation\n",
    "        image_position = ds.ImagePositionPatient\n",
    "        image_orientation = ds.ImageOrientationPatient\n",
    "\n",
    "        # Create the LUT\n",
    "        pixlut = [image_position, image_orientation]\n",
    "        return pixlut\n",
    "\n",
    "    def GetContourPixelData(self, contour, prone = False, feetfirst = False):\n",
    "        # Convert structure data into pixel data using the patient to pixel LUT.\n",
    "        pixeldata = []\n",
    "        pixelX = []\n",
    "        pixelY = []\n",
    "        # For each point in the structure data\n",
    "        # look up the value in the LUT and find the corresponding pixel pair\n",
    "        for p, point in enumerate(contour):\n",
    "            for xv, xval in enumerate(self.pixlut[0]):\n",
    "                if (xval > point[0] and not prone and not feetfirst):\n",
    "                    break\n",
    "                elif (xval < point[0]):\n",
    "                    if feetfirst or prone:\n",
    "                        break\n",
    "            for yv, yval in enumerate(self.pixlut[1]):\n",
    "                if (yval > point[1] and not prone):\n",
    "                    break\n",
    "                elif (yval < point[1] and prone):\n",
    "                    break\n",
    "            pixeldata.append([xv, yv])\n",
    "            pixelX.append(xv) #linePlot\n",
    "            pixelY.append(yv) #lineplot\n",
    "\n",
    "        return pixeldata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b002e6b",
   "metadata": {},
   "source": [
    "## Implenating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc712a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from DicomConverter import DicomConverter\n",
    "\n",
    "# Define the directory containing the CT files\n",
    "ct_dir = 'path/to/ct_files'\n",
    "\n",
    "# Iterate through the directory\n",
    "for filename in os.listdir(ct_dir):\n",
    "    if filename.endswith('.dcm'):\n",
    "        # Create an object of the DicomConverter class and pass the file path as an argument\n",
    "        dc = DicomConverter(os.path.join(ct_dir, filename))\n",
    "        \n",
    "        # Extract the pixel data from the DICOM file using pydicom\n",
    "        pixlut = dc.get_pixlut()\n",
    "        \n",
    "        # Get the contour pixel data\n",
    "        contour_data = dc.GetContourPixelData(pixlut)\n",
    "        \n",
    "        # Save the contour data to a file or do something else with it\n",
    "        with open('path/to/output/'+ filename+'.txt','w') as f:\n",
    "            for item in contour_data:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydicom\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def crop_and_bounding_box(dicom_file_path):\n",
    "    # Read the DICOM file\n",
    "    ds = pydicom.dcmread(dicom_file_path)\n",
    "    # Get the pixel data as a numpy array\n",
    "    pixel_data = ds.pixel_array\n",
    "\n",
    "    # Get the minimum and maximum x and y coordinates of the pixels\n",
    "    min_x, max_x = np.min(np.where(pixel_data > 0)[1]), np.max(np.where(pixel_data > 0)[1])\n",
    "    min_y, max_y = np.min(np.where(pixel_data > 0)[0]), np.max(np.where(pixel_data > 0)[0])\n",
    "    # Crop the image\n",
    "    cropped_image = pixel_data[min_y:max_y, min_x:max_x]\n",
    "\n",
    "    # Create the bounding box\n",
    "    bounding_box = [(min_y, min_x), (max_y, max_x)]\n",
    "\n",
    "    return cropped_image, bounding_box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015c4d8",
   "metadata": {},
   "source": [
    "## Machine learnig model \n",
    "### Data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17238859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pydicom\n",
    "\n",
    "class CTPreprocessing:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load dicom images\n",
    "        dicom_images = [pydicom.dcmread(self.data_path + '/' + f) for f in os.listdir(self.data_path) if f.endswith('.dcm')]\n",
    "\n",
    "        # Extract image data and store it in a list\n",
    "        image_data = []\n",
    "        for d in dicom_images:\n",
    "            image_data.append(d.pixel_array)\n",
    "\n",
    "        return image_data\n",
    "\n",
    "    def crop_data(self, image_data, roi_coordinates):\n",
    "        # Crop images based on the ROI coordinates\n",
    "        cropped_images = []\n",
    "        for image in image_data:\n",
    "            x1, y1, x2, y2 = roi_coordinates\n",
    "            cropped_images.append(image[y1:y2, x1:x2])\n",
    "\n",
    "        return cropped_images\n",
    "    \n",
    "    \n",
    "    def get_bounding_box(self, image):\n",
    "        # Threshold the image to create a binary mask\n",
    "        thresh = image > np.mean(image)\n",
    "        # Label the connected regions in the binary mask\n",
    "        labeled_image = label(thresh)\n",
    "        regions = regionprops(labeled_image)\n",
    "        \n",
    "        # Find the region with the largest area\n",
    "        max_area = 0\n",
    "        for region in regions:\n",
    "            if region.area > max_area:\n",
    "                max_area = region.area\n",
    "                max_region = region\n",
    "\n",
    "        # Get the bounding box coordinates\n",
    "        minr, minc, maxr, maxc = max_region.bbox\n",
    "        bounding_box_coordinates = (minr, minc, maxr, maxc)\n",
    "        \n",
    "        return bounding_box_coordinates\n",
    "\n",
    "    def create_bounding_box(self, image_data, bounding_box_coordinates):\n",
    "        # Create a bounding box around the ROI\n",
    "        bounding_box_images = []\n",
    "        for image in image_data:\n",
    "            x1, y1, x2, y2 = bounding_box_coordinates\n",
    "            bounding_box_images.append(image[y1:y2, x1:x2])\n",
    "\n",
    "        return bounding_box_images\n",
    "\n",
    "    def preprocess_data(self, image_data):\n",
    "        # Scale the image data\n",
    "        scaler = StandardScaler()\n",
    "        image_data = scaler.fit_transform(image_data)\n",
    "\n",
    "        # Shuffle the data\n",
    "        image_data, labels = shuffle(image_data, labels, random_state=42)\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "ct_preprocessing = CTPreprocessing(data_path)\n",
    "image_data = ct_preprocessing.load_data()\n",
    "cropped_images = ct_preprocessing.crop_data(image_data, roi_coordinates)\n",
    "bounding_box_images = ct_preprocessing.create_bounding_box(cropped_images)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Import necessary libraries\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# Define the input layer\n",
    "inputs = Input((256, 256, 1))\n",
    "\n",
    "# Define the encoder layers\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "# Define the decoder layers\n",
    "up1 = UpSampling2D(size=(2, 2))(pool3)\n",
    "conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(up1)\n",
    "up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n",
    "up3 = UpSampling2D(size=(2, 2))(conv5)\n",
    "conv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(up3)\n",
    "\n",
    "# Define the output layer\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv6)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on your labeled CT images dataset\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Use the trained model to predict the ROI in a new CT image\n",
    "prediction = model.predict(x_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe2006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3acec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## anamoly dtection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Create the data generator\n",
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the data flow\n",
    "train_gen = data_gen.flow_from_directory(\n",
    "    'path/to/data/train',\n",
    "    target_size=(256, 256),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "val_gen = data_gen.flow_from_directory(\n",
    "    'path/to/data/val',\n",
    "    target_size=(256, 256),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_gen, steps_per_epoch=len(train_gen), epochs=10, validation_data=val_gen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067adc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "# Load DICOM file\n",
    "ct_image = pydicom.dcmread(\"path/to/ct_image.dcm\")\n",
    "\n",
    "# Extract image data and metadata\n",
    "image_data = ct_image.pixel_array\n",
    "metadata = ct_image.dir()\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Resample image\n",
    "resampled_image = cv2.resize(image_data, (256, 256))\n",
    "\n",
    "# Normalize image\n",
    "normalized_image = cv2.normalize(resampled_image, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "# Crop image\n",
    "cropped_image = normalized_image[50:200, 50:200]\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Use model to predict on new image\n",
    "prediction = model.predict(new_image)\n",
    "\n",
    "# Analyze prediction to determine if anomaly is present\n",
    "if prediction > 0.5:\n",
    "    print(\"Anomaly detected\")\n",
    "else:\n",
    "    print(\"No anomaly detected\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
